{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"DNN_TAE_TPU_multicore_resnet.ipynb","provenance":[{"file_id":"1pbBtkiU0vWqyQ1GBrTjHQwu1io53BrTi","timestamp":1614835397296},{"file_id":"1swV6ADJFNASXjbC-Z2g6UvmE_w9ERXS3","timestamp":1614436176970},{"file_id":"194Osx6sTU2p8OwlHfuBeEObjeF3YOph8","timestamp":1614311498018}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyNltVu1vMV41R0GzsSMGM4U"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9bb1f0e87df5494d878764149d4e69dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3554bb6c40bd433b8c2308fba893aafb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b393a27b61c44c1ab4926086a9544b1b","IPY_MODEL_30667471ebcb4eb587b3a808142d208a"]}},"3554bb6c40bd433b8c2308fba893aafb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b393a27b61c44c1ab4926086a9544b1b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_03fdf1fdcc4547239405829c94c1ce94","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"","max":137,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0bacea686e3e4cf39cda5292c5ff75d5"}},"30667471ebcb4eb587b3a808142d208a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_189845fc89734f63a68a4e9a49a61c13","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/137 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f1b273d545f24b808d26ade41681d6a2"}},"03fdf1fdcc4547239405829c94c1ce94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0bacea686e3e4cf39cda5292c5ff75d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"189845fc89734f63a68a4e9a49a61c13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f1b273d545f24b808d26ade41681d6a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"70xUPM3gAmO2"},"source":["## Using multicore TPU to accelerate Neural Network Trianing"]},{"cell_type":"markdown","metadata":{"id":"NWEC8p1pA4wi"},"source":["\n","\n","\n","\n","**Step 1.**\n","Install the pytorch XLA libreries to communicate with the TPU\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"vTIDZnFeVM4s","executionInfo":{"status":"ok","timestamp":1620626491878,"user_tz":-330,"elapsed":1398,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["import os\n","assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kgAIKammjUrh","executionInfo":{"status":"ok","timestamp":1620626513531,"user_tz":-330,"elapsed":23040,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}},"outputId":"6692afaf-9833-4e41-d873-d936e0c96da8"},"source":["!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting cloud-tpu-client==0.10\n","  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n","Collecting torch-xla==1.8\n","\u001b[?25l  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl (144.6MB)\n","\u001b[K     |████████████████████████████████| 144.6MB 27kB/s \n","\u001b[?25hCollecting google-api-python-client==1.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n","\u001b[K     |████████████████████████████████| 61kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n","Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n","Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.17.4)\n","Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n","Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.28.1)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.7.2)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (20.9)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (56.1.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.12.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n","\u001b[31mERROR: earthengine-api 0.1.260 has requirement google-api-python-client<2,>=1.12.1, but you'll have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n","Installing collected packages: google-api-python-client, cloud-tpu-client, torch-xla\n","  Found existing installation: google-api-python-client 1.12.8\n","    Uninstalling google-api-python-client-1.12.8:\n","      Successfully uninstalled google-api-python-client-1.12.8\n","Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0 torch-xla-1.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"el4FVkBVNE2G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620626568585,"user_tz":-330,"elapsed":78086,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}},"outputId":"f59d2dfd-653d-478d-88f6-a2f8759220ba"},"source":["import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader,random_split\n","from torch.utils.data.distributed import DistributedSampler\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.decomposition import PCA\n","\n","# import torch xla APIs\n","\n","import torch_xla\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.parallel_loader as pl\n","import torch_xla.distributed.xla_multiprocessing as xmp"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:root:Waiting for TPU to be start up with version pytorch-1.8...\n","WARNING:root:Waiting for TPU to be start up with version pytorch-1.8...\n","WARNING:root:Waiting for TPU to be start up with version pytorch-1.8...\n","WARNING:root:TPU has started up successfully with version pytorch-1.8\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"A9XUiRviA9ej","executionInfo":{"status":"ok","timestamp":1620626568586,"user_tz":-330,"elapsed":78076,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["import pickle"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWt8R5xu0ypq","executionInfo":{"status":"ok","timestamp":1620626568587,"user_tz":-330,"elapsed":78068,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["#train_size=int(0.4*(unprocessed_data.shape[0]))\n","# val_size=len(unprocessed_data) - train_size\n","# print(train_size,val_size)\n","# train_ds,_ = random_split(unprocessed_data,[train_size,val_size])"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mGPeq0ZlCPjk"},"source":["**Step 2.** Get the dataset\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iInH51e64fI5","executionInfo":{"status":"ok","timestamp":1620626590976,"user_tz":-330,"elapsed":100450,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}},"outputId":"449e517a-24a8-438f-9344-b52cdb04f030"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v_tmol9vDTKh","executionInfo":{"status":"ok","timestamp":1620626590977,"user_tz":-330,"elapsed":100442,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["#unscaled = np.load('/content/drive/MyDrive/Autoencoding/Unscaled_data_sorted.npy')\n","#!cd /content/drive/MyDrive/"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNdlhvqPBm48","executionInfo":{"status":"ok","timestamp":1620626590978,"user_tz":-330,"elapsed":100432,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}},"outputId":"f2a378a7-b3c1-4dfa-b465-d9cd8e58508e"},"source":["ls -lsrt"],"execution_count":8,"outputs":[{"output_type":"stream","text":["total 8\n","4 drwxr-xr-x 1 root root 4096 May  6 13:44 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n","4 drwx------ 6 root root 4096 May 10 06:03 \u001b[01;34mdrive\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"peamKBEwDkTm","executionInfo":{"status":"ok","timestamp":1620626590978,"user_tz":-330,"elapsed":100425,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["#train_dataset = unscaled[unscaled[:,0] < 2.0]\n","#train_dataset = pickle.load(open('all_clw_1780_4047_reshaped.pkl','rb'))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Nod8avbEjIW","executionInfo":{"status":"ok","timestamp":1620626590979,"user_tz":-330,"elapsed":100419,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["#train_dataset.shape"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ggd3OgrDDUqX","executionInfo":{"status":"ok","timestamp":1620626590979,"user_tz":-330,"elapsed":100412,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["# pca_whiten = PCA(whiten=True)\n","\n","# train_dataset = pca_whiten.fit_transform(train_dataset)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJyGMabRE3hm","executionInfo":{"status":"ok","timestamp":1620626590980,"user_tz":-330,"elapsed":100406,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["#train_dataset = torch.from_numpy(train_dataset)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"bTuBX-a-3SAl","executionInfo":{"status":"ok","timestamp":1620626678352,"user_tz":-330,"elapsed":187771,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["#train_dataset =  torch.load('/content/drive/MyDrive/Autoencoding/raw_cv_whiten.pt')\n","#torch.save(train_dataset,'xyz_traj_whitten.pt')\n","train_dataset = torch.load('/content/drive/MyDrive/1780_to_4047_files/xyz_traj_whitten.pt')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"vPRg_H8WDfxz","executionInfo":{"status":"ok","timestamp":1620626678353,"user_tz":-330,"elapsed":187765,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["# Define Parameters\n","FLAGS = {}\n","#FLAGS['data_dir'] = \"/tmp/cifar\"\n","FLAGS['batch_size'] = 2056\n","FLAGS['num_workers'] = 4\n","FLAGS['max_learning_rate'] = 0.001\n","#FLAGS['grad_clip']  = 0.1\n","FLAGS['weight_decay'] = 1e-4\n","FLAGS['opt_func']  = torch.optim.Adam\n","#FLAGS['momentum'] = 0.9\n","FLAGS['num_epochs'] = 5\n","FLAGS['num_cores'] = 8 \n","FLAGS['log_steps'] = 20\n","FLAGS['metrics_debug'] = False"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QN-7--Sc3hTP"},"source":["** warp the dataloader for parallelization**"]},{"cell_type":"code","metadata":{"id":"-eldLtL94efF","executionInfo":{"status":"ok","timestamp":1620626678354,"user_tz":-330,"elapsed":187760,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["#SERIAL_EXEC = xmp.MpSerialExecutor()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"jZzAIbBw37f_","executionInfo":{"status":"ok","timestamp":1620626678355,"user_tz":-330,"elapsed":187754,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["#train_dl = DataLoader(train_ds,batch_size,shuffle=True)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"59EpxOR9NE2Q","executionInfo":{"status":"ok","timestamp":1620626678355,"user_tz":-330,"elapsed":187747,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["# def make_4_dim(data):\n","#     data=torch.unsqueeze(data,1)\n","#     data = torch.unsqueeze(data,3)\n","#     return data\n","\n","# def make_2_dim(data):\n","#     data=torch.squeeze(data,1)\n","#     data = torch.squeeze(data,2)\n","#     return data"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"FjVkxzecNE2R","executionInfo":{"status":"ok","timestamp":1620626678356,"user_tz":-330,"elapsed":187742,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["def lin_block(in_dim,out_dim,bias=True):\n","    layers = [nn.Linear(in_dim,out_dim,bias= True),\n","              #nn.BatchNorm2d(out_dim),\n","              nn.LeakyReLU(negative_slope=0.2,inplace=True)]\n","    return nn.Sequential(*layers)\n","\n","# def conv_block2(in_channels,out_channels,kernel_size,stride,padding,pool=False):\n","#     layers = [nn.Linear(in_channels=in_channels,out_channels=out_channels,kernel_size=kernel_size,\n","#                         stride=stride,padding=padding),\n","#               nn.BatchNorm2d(out_channels),\n","#               nn.LeakyReLU(negative_slope=0.2,inplace=True)]\n","#     return nn.Sequential(*layers)\n","    \n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V-UagiRdyEab","executionInfo":{"status":"ok","timestamp":1620627061587,"user_tz":-330,"elapsed":1180,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}},"outputId":"22962174-53dd-4be9-f0da-d2fe2fc1096d"},"source":[""],"execution_count":61,"outputs":[{"output_type":"stream","text":["256\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qM_YehVwNE2R","executionInfo":{"status":"ok","timestamp":1620627147960,"user_tz":-330,"elapsed":1096,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["#hidden_layers = [64,128,256]\n","class Resnet9(nn.Module):\n","      def __init__(self, in_dim,hidden_layers):\n","        super().__init__()\n","        \n","        # Encode1\n","        \n","        self.lin1 = lin_block(in_dim,hidden_layers[0])         \n","        self.lin2 = lin_block(hidden_layers[0],hidden_layers[1])\n","        self.lin3 = lin_block(hidden_layers[1],hidden_layers[2]) \n","        \n","        self.res1 = nn.Sequential(lin_block(hidden_layers[2], hidden_layers[2]),  \n","                                  lin_block(hidden_layers[2], hidden_layers[2]))\n","        \n","        #Encode2\n","        self.lin4 = lin_block(hidden_layers[2],hidden_layers[1])         \n","        self.lin5 = lin_block(hidden_layers[1],hidden_layers[0])\n","        \n","        self.res2 = nn.Sequential(lin_block(hidden_layers[0], hidden_layers[0]),  \n","                                  lin_block(hidden_layers[0], hidden_layers[0]))\n","        self.lin6 = nn.Linear(hidden_layers[0],in_dim)\n","        \n","         # Decode1\n","        \n","        self.lin7 = lin_block(in_dim,hidden_layers[0])         \n","        self.lin8 = lin_block(hidden_layers[0],hidden_layers[1])\n","        self.lin9 = lin_block(hidden_layers[1],hidden_layers[2]) \n","        \n","        self.res3 = nn.Sequential(lin_block(hidden_layers[2], hidden_layers[2]),  \n","                                  lin_block(hidden_layers[2], hidden_layers[2]))\n","        \n","        #Decode2\n","        self.lin10 = lin_block(hidden_layers[2],hidden_layers[1])         \n","        self.lin11 = lin_block(hidden_layers[1],hidden_layers[0])\n","        \n","        self.res4 = nn.Sequential(lin_block(hidden_layers[0], hidden_layers[0]),  \n","                                  lin_block(hidden_layers[0], hidden_layers[0]))\n","        self.lin12 = nn.Linear(hidden_layers[0],in_dim)\n","        \n","      def encode(self,in_data):\n","          out = self.lin1(in_data.float())\n","          out = self.lin2(out)\n","          out = self.lin3(out)\n","          out = self.res1(out)+out\n","          out = self.lin4(out)\n","          out = self.lin5(out)\n","          out = self.res2(out)+out\n","          out = self.lin6(out)\n","          return out\n","           \n","      def decode(self,lat_data):\n","          out = self.lin7(lat_data.float())\n","          out = self.lin8(out)\n","          out = self.lin9(out)\n","          out = self.res3(out)+out\n","          out = self.lin10(out)\n","          out = self.lin11(out)\n","          out = self.res4(out)+out\n","          out = self.lin12(out)\n","          return out\n","      \n","        "],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"id":"nX4AvqDn3E0I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620627244713,"user_tz":-330,"elapsed":1220,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}},"outputId":"9c7a2585-836c-4cdd-9c81-878b6050368d"},"source":["hidden_layers = [256,128,64,4]\n","in_dim = 2\n","print(hidden_layers[0])"],"execution_count":100,"outputs":[{"output_type":"stream","text":["256\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lQlH69Jn5Xw4","executionInfo":{"status":"ok","timestamp":1620627244715,"user_tz":-330,"elapsed":945,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["WRAPPED_MODEL = xmp.MpModelWrapper(Resnet9(in_dim,hidden_layers))"],"execution_count":101,"outputs":[]},{"cell_type":"code","metadata":{"id":"3FPxg0XENJzq","executionInfo":{"status":"ok","timestamp":1620627244716,"user_tz":-330,"elapsed":720,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["# # def get_default_device():\n","# #     \"\"\"Pick GPU if available, else CPU\"\"\"\n","# #     if torch.cuda.is_available():\n","# #         return torch.device('cuda')\n","# #     else:\n","# #         return torch.device('cpu')\n","    \n","# def to_device(data, device):\n","#     \"\"\"Move tensor(s) to chosen device\"\"\"\n","#     if isinstance(data, (list,tuple)):\n","#         return [to_device(x, device) for x in data]\n","#     return data.to(device, non_blocking=True)\n","\n","# class DeviceDataLoader():\n","#     \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","#     def __init__(self, dl, device):\n","#         self.dl = dl\n","#         self.device = device\n","        \n","#     def __iter__(self):\n","#         \"\"\"Yield a batch of data after moving it to device\"\"\"\n","#         for b in self.dl: \n","#             yield to_device(b, self.device)\n","\n","#     def __len__(self):\n","#         \"\"\"Number of batches\"\"\"\n","#         return len(self.dl)"],"execution_count":102,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPrgUB273eaX","executionInfo":{"status":"ok","timestamp":1620627246633,"user_tz":-330,"elapsed":2398,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["lag = 8\n","train_data = train_dataset[:-lag]\n","shifted_train_data = train_dataset[lag:]\n","transformed_train_data = torch.hstack((train_data,shifted_train_data))"],"execution_count":103,"outputs":[]},{"cell_type":"code","metadata":{"id":"rjFXI6Cr5avN","executionInfo":{"status":"ok","timestamp":1620627246636,"user_tz":-330,"elapsed":2192,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["def training_step(data,encoder):\n","    training_dat = data[:,0:2]\n","    #training_dat = make_4_dim(training_dat)\n","    shifted_dat = data[:,2:4]\n","    out = encoder.encode(training_dat)\n","    out = encoder.decode(out)\n","    #out = make_2_dim(out)\n","    criterion = nn.MSELoss()\n","    loss = criterion(out.float(),shifted_dat.float())\n","    return loss"],"execution_count":104,"outputs":[]},{"cell_type":"code","metadata":{"id":"F1TxFdaiNE2U","executionInfo":{"status":"ok","timestamp":1620627246637,"user_tz":-330,"elapsed":1972,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["# def training_step(data,encoder):\n","#     training_dat = data\n","#     training_dat = make_4_dim(training_dat)\n","#     out = encoder.encode(training_dat)\n","#     out = encoder.decode(out)\n","#     out = make_2_dim(out)\n","#     criterion = nn.MSELoss()\n","#     loss = criterion(out.float(),data.float())\n","#     return loss\n","\n","# def evaluate(model,val_loader):\n","#     for data in val_loader:\n","#         val_dat = data\n","#         val_dat = make_4_dim(val_dat)\n","#         out = model.encode(val_dat)\n","#         out = model.decode(out)\n","#         out = make_2_dim(out)\n","#         criterion = nn.MSELoss()\n","#         loss = criterion(out.float(),data.float())\n","#         return {'val_loss':loss}"],"execution_count":105,"outputs":[]},{"cell_type":"code","metadata":{"id":"L7nSGimr4sxK","executionInfo":{"status":"ok","timestamp":1620627246637,"user_tz":-330,"elapsed":1713,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["from tqdm.notebook import tqdm"],"execution_count":106,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_K9IqlW7U0u","executionInfo":{"status":"ok","timestamp":1620627246639,"user_tz":-330,"elapsed":1521,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":[""],"execution_count":106,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLwvDBK95tTk","executionInfo":{"status":"ok","timestamp":1620627246639,"user_tz":-330,"elapsed":1233,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["# def prepare_data(unprocessed_data):\n","\n","#       train_ds = unprocessed_data[:]\n","#       train_ds = train_ds -torch.mean(train_ds,0) # Mean free\n","\n","#       pca_whiten = PCA(whiten=True)                     # Whiten data\n","#       train_ds = pca_whiten.fit_transform(train_ds)\n","\n","#       train_ds = torch.tensor(train_ds)                  # as tensor\n","#       return train_ds"],"execution_count":107,"outputs":[]},{"cell_type":"code","metadata":{"id":"0LAx5AzONE2V","executionInfo":{"status":"ok","timestamp":1620627246640,"user_tz":-330,"elapsed":985,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["#@torch.no_grad()\n","def fit_one_cycle(FLAGS):\n","    \n","    torch.manual_seed(1234)\n","    history = []\n","\n","    \n","\n","    #train_dataset = SERIAL_EXEC.run(prepare_data(unprocessed_data))\n","    #train_dataset = prepare_data(unprocessed_data)\n","    train_sampler = DistributedSampler(transformed_train_data,\n","                                       num_replicas=xm.xrt_world_size(),\n","                                       #num_replicas=8,\n","                                       rank= xm.get_ordinal(),\n","                                       shuffle=True)\n","    train_loader  = DataLoader(transformed_train_data,\n","                               batch_size=FLAGS['batch_size'],\n","                               sampler= train_sampler,\n","                               num_workers=FLAGS['num_workers'])\n","    \n","    # Scale learning rate to no of torch devices\n","    max_lr = FLAGS['max_learning_rate']*xm.xrt_world_size()\n","\n","    # Get loss function, optimizer, and model\n","    device = xm.xla_device()\n","    encoder = WRAPPED_MODEL.to(device)\n","    opt_func = FLAGS['opt_func']\n","    # set up custom optimizer with weight decay\n","    optimizer = opt_func(encoder.parameters(),\n","                         FLAGS['max_learning_rate'],\n","                         weight_decay=FLAGS['weight_decay'])\n","    \n","    # set up one_cycle learning rate scheduler\n","    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n","                                                FLAGS['max_learning_rate'],\n","                                               epochs=FLAGS['num_epochs'],\n","                                               steps_per_epoch=len(train_loader))\n","    \n","    \n","    # crate the loop for training\n","    \n","    for epoch in range(FLAGS['num_epochs']):\n","        # Training Phase\n","        encoder.train()\n","        train_losses = []\n","        para_loader = pl.ParallelLoader(train_loader,[device]).per_device_loader(device)\n","        #train_loop_fn(para_loader.per_device_loader(device))\n","        xm.master_print(\"Finished training epoch {}\".format(epoch))\n","        \n","        for batch in tqdm(para_loader):\n","            \n","            loss = training_step(batch,encoder)\n","            train_losses.append(loss)\n","            loss.backward()\n","            \n","            # Gradient clipping\n","            #if grad_clip:\n","            #nn.utils.clip_grad_value_(encoder.parameters(),\n","            #                             FLAGS['grad_clip'])\n","            xm.optimizer_step(optimizer)\n","            optimizer.zero_grad()\n","            \n","            sched.step()\n","        # Validation Phase    \n","        #result = evaluate(model,val_loader)\n","        train_loss = torch.stack(train_losses).mean().item()\n","        print('train_loss{:.4f}'.format(train_loss))\n","        history.append(train_loss)\n","        history_ten = torch.tensor(history)\n","        xm.save(encoder.state_dict(),'encoder_state_dict_resnet.pth')\n","        xm.save(history_ten,'history_resnet.pth')\n","    return history_ten"],"execution_count":108,"outputs":[]},{"cell_type":"code","metadata":{"id":"MejGFvce5Ce5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620627248704,"user_tz":-330,"elapsed":2716,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}},"outputId":"6cdb5874-eefc-48d4-d24c-578e286753fb"},"source":["train_sampler = DistributedSampler(transformed_train_data,\n","                                       num_replicas=xm.xrt_world_size(),\n","                                       #num_replicas=8,\n","                                       rank= xm.get_ordinal(),\n","                                       shuffle=True)\n","train_loader  = DataLoader(transformed_train_data,\n","                               batch_size=FLAGS['batch_size'],\n","                               sampler= train_sampler,\n","                               num_workers=FLAGS['num_workers'])\n","for batch in train_loader:\n","    print(batch.shape)\n","    break"],"execution_count":109,"outputs":[{"output_type":"stream","text":["torch.Size([2056, 612])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_RCZ-4pZPFjm"},"source":["## Make the Map Function "]},{"cell_type":"code","metadata":{"id":"MsR7hC_VF8Eg","executionInfo":{"status":"ok","timestamp":1620627248705,"user_tz":-330,"elapsed":1631,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["#torch.unsqueeze(batch,dim=0).shape"],"execution_count":110,"outputs":[]},{"cell_type":"code","metadata":{"id":"GBIzTqfM42lJ","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9bb1f0e87df5494d878764149d4e69dc","3554bb6c40bd433b8c2308fba893aafb","b393a27b61c44c1ab4926086a9544b1b","30667471ebcb4eb587b3a808142d208a","03fdf1fdcc4547239405829c94c1ce94","0bacea686e3e4cf39cda5292c5ff75d5","189845fc89734f63a68a4e9a49a61c13","f1b273d545f24b808d26ade41681d6a2"]},"executionInfo":{"status":"error","timestamp":1620627270613,"user_tz":-330,"elapsed":23256,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}},"outputId":"603f642e-e684-4c9f-cf21-52cc13f210b6"},"source":["def map_fn(rank,flags):\n","    global FLAGS\n","    FLAGS = flags \n","    torch.set_default_tensor_type('torch.FloatTensor')\n","    #history = []\n","    history_ten = fit_one_cycle(FLAGS)\n","    # if rank == 0:\n","    # # Retrieve tensors that are on TPU core 0 and plot.\n","    #    xm.save(encoder_state_dict,'encoder_state_dict.pth')\n","\n","if __name__ == '__main__':\n","          xmp.spawn(map_fn,args = (FLAGS,),nprocs=FLAGS['num_cores'],\n","          start_method='fork')"],"execution_count":111,"outputs":[{"output_type":"stream","text":["Finished training epoch 0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9bb1f0e87df5494d878764149d4e69dc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=137.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Exception in device=TPU:6: tensorflow/compiler/xla/xla_client/mesh_service.cc:331 : Failed to retrieve mesh configuration: Connection reset by peer (14)\n","Exception in device=TPU:3: tensorflow/compiler/xla/xla_client/mesh_service.cc:331 : Failed to retrieve mesh configuration: Connection reset by peer (14)\n","Exception in device=TPU:7: tensorflow/compiler/xla/xla_client/mesh_service.cc:331 : Failed to retrieve mesh configuration: Connection reset by peer (14)\n","Exception in device=TPU:5: tensorflow/compiler/xla/xla_client/mesh_service.cc:331 : Failed to retrieve mesh configuration: Connection reset by peer (14)\n","Exception in device=TPU:2: tensorflow/compiler/xla/xla_client/mesh_service.cc:331 : Failed to retrieve mesh configuration: Connection reset by peer (14)\n","Exception in device=TPU:4: tensorflow/compiler/xla/xla_client/mesh_service.cc:331 : Failed to retrieve mesh configuration: Connection reset by peer (14)\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n","    _start_fn(index, pf_cfg, fn, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n","    _start_fn(index, pf_cfg, fn, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n","    _start_fn(index, pf_cfg, fn, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n","    _start_fn(index, pf_cfg, fn, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n","    _start_fn(index, pf_cfg, fn, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n","    _start_fn(index, pf_cfg, fn, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 322, in _start_fn\n","    _setup_replication()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 322, in _start_fn\n","    _setup_replication()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 322, in _start_fn\n","    _setup_replication()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 322, in _start_fn\n","    _setup_replication()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 322, in _start_fn\n","    _setup_replication()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 314, in _setup_replication\n","    device = xm.xla_device()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 322, in _start_fn\n","    _setup_replication()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 314, in _setup_replication\n","    device = xm.xla_device()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 314, in _setup_replication\n","    device = xm.xla_device()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 314, in _setup_replication\n","    device = xm.xla_device()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 314, in _setup_replication\n","    device = xm.xla_device()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 231, in xla_device\n","    devkind=devkind if devkind is not None else None)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 314, in _setup_replication\n","    device = xm.xla_device()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 231, in xla_device\n","    devkind=devkind if devkind is not None else None)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 231, in xla_device\n","    devkind=devkind if devkind is not None else None)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 231, in xla_device\n","    devkind=devkind if devkind is not None else None)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 136, in get_xla_supported_devices\n","    xla_devices = _DEVICES.value\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 231, in xla_device\n","    devkind=devkind if devkind is not None else None)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 231, in xla_device\n","    devkind=devkind if devkind is not None else None)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 136, in get_xla_supported_devices\n","    xla_devices = _DEVICES.value\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 136, in get_xla_supported_devices\n","    xla_devices = _DEVICES.value\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 136, in get_xla_supported_devices\n","    xla_devices = _DEVICES.value\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/utils/utils.py\", line 32, in value\n","    self._value = self._gen_fn()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 136, in get_xla_supported_devices\n","    xla_devices = _DEVICES.value\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 136, in get_xla_supported_devices\n","    xla_devices = _DEVICES.value\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/utils/utils.py\", line 32, in value\n","    self._value = self._gen_fn()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/utils/utils.py\", line 32, in value\n","    self._value = self._gen_fn()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 18, in <lambda>\n","    _DEVICES = xu.LazyProperty(lambda: torch_xla._XLAC._xla_get_devices())\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/utils/utils.py\", line 32, in value\n","    self._value = self._gen_fn()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/utils/utils.py\", line 32, in value\n","    self._value = self._gen_fn()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/utils/utils.py\", line 32, in value\n","    self._value = self._gen_fn()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 18, in <lambda>\n","    _DEVICES = xu.LazyProperty(lambda: torch_xla._XLAC._xla_get_devices())\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 18, in <lambda>\n","    _DEVICES = xu.LazyProperty(lambda: torch_xla._XLAC._xla_get_devices())\n","RuntimeError: tensorflow/compiler/xla/xla_client/mesh_service.cc:331 : Failed to retrieve mesh configuration: Connection reset by peer (14)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 18, in <lambda>\n","    _DEVICES = xu.LazyProperty(lambda: torch_xla._XLAC._xla_get_devices())\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 18, in <lambda>\n","    _DEVICES = xu.LazyProperty(lambda: torch_xla._XLAC._xla_get_devices())\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_xla/core/xla_model.py\", line 18, in <lambda>\n","    _DEVICES = xu.LazyProperty(lambda: torch_xla._XLAC._xla_get_devices())\n","RuntimeError: tensorflow/compiler/xla/xla_client/mesh_service.cc:331 : Failed to retrieve mesh configuration: Connection reset by peer (14)\n","RuntimeError: tensorflow/compiler/xla/xla_client/mesh_service.cc:331 : Failed to retrieve mesh configuration: Connection reset by peer (14)\n","RuntimeError: tensorflow/compiler/xla/xla_client/mesh_service.cc:331 : Failed to retrieve mesh configuration: Connection reset by peer (14)\n","RuntimeError: tensorflow/compiler/xla/xla_client/mesh_service.cc:331 : Failed to retrieve mesh configuration: Connection reset by peer (14)\n","RuntimeError: tensorflow/compiler/xla/xla_client/mesh_service.cc:331 : Failed to retrieve mesh configuration: Connection reset by peer (14)\n"],"name":"stderr"},{"output_type":"error","ename":"ProcessExitedException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-111-7307b854fe7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           xmp.spawn(map_fn,args = (FLAGS,),nprocs=FLAGS['num_cores'],\n\u001b[0;32m---> 13\u001b[0;31m           start_method='fork')\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0merror_pid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfailed_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mexit_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                     \u001b[0msignal_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 )\n\u001b[1;32m    138\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mProcessExitedException\u001b[0m: process 0 terminated with signal SIGSEGV"]}]},{"cell_type":"code","metadata":{"id":"fuWTM2tJHpw7","executionInfo":{"status":"aborted","timestamp":1620627270612,"user_tz":-330,"elapsed":22707,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["history = torch.load('history_resnet.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qPFv-qaEIGYJ","executionInfo":{"status":"aborted","timestamp":1620626842362,"user_tz":-330,"elapsed":351618,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["plt.plot(history)\n","plt.xlabel = ('Epochs')\n","plt.ylabel = ('MSE_loss')\n","plt.savefig('loss.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvZncFUB6JUk","executionInfo":{"status":"aborted","timestamp":1620626842362,"user_tz":-330,"elapsed":351615,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["encoder = Resnet9(1,1);decoder =Resnet9(1,1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5kOs5AQuGcVM","executionInfo":{"status":"aborted","timestamp":1620626842363,"user_tz":-330,"elapsed":351614,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["decoder.load_state_dict(torch.load('encoder_state_dict.pth'))\n","encoder.load_state_dict(torch.load('encoder_state_dict_1.pth'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AeyEmc02Rz0G","executionInfo":{"status":"aborted","timestamp":1620626842363,"user_tz":-330,"elapsed":351613,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["torch.all(torch.eq(decoder.state_dict(),encoder.state_dict()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vxtwrckbGmgz","executionInfo":{"status":"aborted","timestamp":1620626842364,"user_tz":-330,"elapsed":351612,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["encoder.encode"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HSoXRZbFLol6","executionInfo":{"status":"aborted","timestamp":1620626842364,"user_tz":-330,"elapsed":351611,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["import torch\n","history = torch.load('history_4.pth')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VjBZEsEzL70p","executionInfo":{"status":"aborted","timestamp":1620626842365,"user_tz":-330,"elapsed":351610,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2NXaHp0-Oc-V","executionInfo":{"status":"aborted","timestamp":1620626842365,"user_tz":-330,"elapsed":351600,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":["  for epoch in range(FLAGS['num_epochs']):\n","    print (epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TH1TapBOWpiL","executionInfo":{"status":"aborted","timestamp":1620626842366,"user_tz":-330,"elapsed":351599,"user":{"displayName":"Asit Pal","photoUrl":"","userId":"06025537331293253402"}}},"source":[""],"execution_count":null,"outputs":[]}]}